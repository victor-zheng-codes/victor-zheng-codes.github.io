<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Testing Automation Framework | Victor Zheng</title>
<meta name=keywords content><meta name=description content="Test Automation Framework The Test Automation Program was one of the main projects that I worked on while at the Ministry of Education of the Government of Ontario.
The code is open-source and is a comprehensive, end-to-end testing framework for UI testing and reporting. The original developers had a multi-repo model which I combined into a mono-repo to enable easier versioning, feature enhancements, and documentation.
The full, open-source framework is available here: github."><meta name=author content="Victor Zheng"><link rel=canonical href=http://localhost:1313/posts/automation-framework/><link crossorigin=anonymous href=/assets/css/stylesheet.bccfefac377bc340f06c260aed1bddf49a4354816d7c570d6aac75a997986c95.css integrity="sha256-vM/vrDd7w0DwbCYK7Rvd9JpDVIFtfFcNaqx1qZeYbJU=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href="https://github.com/victor-zheng-codes/Personal-Website/blob/main/static/chess_design_favicon.png?raw=true"><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/automation-framework/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Testing Automation Framework"><meta property="og:description" content="Test Automation Framework The Test Automation Program was one of the main projects that I worked on while at the Ministry of Education of the Government of Ontario.
The code is open-source and is a comprehensive, end-to-end testing framework for UI testing and reporting. The original developers had a multi-repo model which I combined into a mono-repo to enable easier versioning, feature enhancements, and documentation.
The full, open-source framework is available here: github."><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/posts/automation-framework/"><meta property="og:image" content="http://localhost:1313/posts/post-files/internships/test-automation-view.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-02T12:31:16-04:00"><meta property="article:modified_time" content="2024-09-02T12:31:16-04:00"><meta property="og:site_name" content="Victor Zheng's Blog Site"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/posts/post-files/internships/test-automation-view.png"><meta name=twitter:title content="Testing Automation Framework"><meta name=twitter:description content="Test Automation Framework The Test Automation Program was one of the main projects that I worked on while at the Ministry of Education of the Government of Ontario.
The code is open-source and is a comprehensive, end-to-end testing framework for UI testing and reporting. The original developers had a multi-repo model which I combined into a mono-repo to enable easier versioning, feature enhancements, and documentation.
The full, open-source framework is available here: github."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"Testing Automation Framework","item":"http://localhost:1313/posts/automation-framework/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Testing Automation Framework","name":"Testing Automation Framework","description":"Test Automation Framework The Test Automation Program was one of the main projects that I worked on while at the Ministry of Education of the Government of Ontario.\nThe code is open-source and is a comprehensive, end-to-end testing framework for UI testing and reporting. The original developers had a multi-repo model which I combined into a mono-repo to enable easier versioning, feature enhancements, and documentation.\nThe full, open-source framework is available here: github.","keywords":[""],"articleBody":"Test Automation Framework The Test Automation Program was one of the main projects that I worked on while at the Ministry of Education of the Government of Ontario.\nThe code is open-source and is a comprehensive, end-to-end testing framework for UI testing and reporting. The original developers had a multi-repo model which I combined into a mono-repo to enable easier versioning, feature enhancements, and documentation.\nThe full, open-source framework is available here: github.com/zzzrst/AutomationTestingProgram.\nAll thoughts are my own and I have redacted any personal information and team information. The main goal for all my blogs is to provide a personal reflection of different years of my life.\nBackground The framework is Keyword Driven, with Selenium 4.0 running in the background and abstractions made to make it executable with test steps defined in Excel or Oracle. The thinking for making test step definitions defined in Excel is that it allows for the ease of sending the file via email, and for the non-technical team members to use the framework for testing. The need to understand how the scripting is done is abstracted and so PM or someone with no technical knowledge can still generate and understand tests. See my section below on BDD for some thoughts on this though.\nThe framework interacts with the Oracle DB or Excel test cases before parsing the results into Test Step, Test Suites, and Test Sets using the builder design pattern. Each Test Suite is built, then Test Cases are added to the Test Suite, and then Test Steps are added to the Test Case. When we execute the tests, we start from the Test Steps and report results to the Test Case, which in turn reports back to the Test Suite. The framework would read the ALM Test Suite and Test Case definitions, query the Oracle DB within one table for the test step ordering, and then execute the test via C#. Before reporting results to ALM or any other testing reporting platform.\nThe framework also allows for a Traceability Matrix to be used to map requirements for testing. Traceability is usually done in an Excel file and mapped directly to test cases and steps which can be in a separate tab in the same Excel.\nWhen I first joined the team at the Ministry of Education, we were working with an Oracle Database which stored our test cases alongside Micro Focus’ ALM project management platform. As in all companies, migration projects are always underway.\nWe were moving to Microsoft’s SharePoint Online from on-prem SharePoint and to Azure DevOps from Microsoft TFS. With Azure DevOps, work items would be logged into DevOps and manual tests would also no longer be done in ALM.\nTherefore, there was a necessary need to investigate how we could migrate our tests to Azure DevOps and get results published to Azure DevOps instead of simply ALM. The quest began to build this new framework.\nWhy Azure DevOps Microsoft Azure is the future, and it enables continuous integration and continuous delivery, which will speed up product delivery, and bring development to production timelines faster. The barrier between development and operations teams will drastically decrease and we can more quickly iterate to build better products. Using TFS, we would never be able to say we are Agile as we would always be waiting for gates to be approved and deployments to be manually executed.\nMicro Focus’ ALM is an on-prem server, which is hard to use, difficult to configure, and filled with buttons which we will never need to use and are hard to understand. It runs very slowly, does not store build/deployment information, and does not have a linkage between code and executions. It also does not allow us to link test cases to different builds, so we are not 100% sure that the tests we are executing are in the right environments. Setting up ALM itself requires a ton of configuring and downloading archaic software from the web.\nWhen we use Azure DevOps (like Jira), we can directly see the linkage between defects and code changes. It also has many integrations with popular products directly from its marketplace. It has task groups available, and agent pools for deployment. It is Team Foundation Server but much more modern and with Git. The main benefit, however, is that it is on the cloud and accessible with any web browser. This means that simply accessing defects does not take a few minutes and logging issues can be quick and simple. It is a modern approach to software development.\nWhy I took up the project At first, I wanted to understand how ALM communicated with Oracle and how the Selenium running in the background worked. However, I also noticed that our methodologies were lacking some major items such as version control, ease of updating, and the ability to see the big picture. I also had major questions about how to update the framework to fit the needs of QA teams. For instance, I remember asking how we could update browser versions or add new features to execute scripts against an Oracle DB. In addition, the need to interact with a database using SQL is not easy. Looking at a table in a database does not give you information on what is being run. One month into my internship, I landed on the migration project and some initial source-code of a framework which was discussed 5 years ago. The blueprint was there, but the framework still was not finished. The framework needed major tune-ups and fixing so that it would be usable with the modern-day approaches.\nHow I managed the project\nPersonally, I excel in ambiguous projects which require careful thinking, strategizing, and planning to achieve. However, the main problem with ambiguity is that there is not always a clear idea of what needs to be done. My manager and my team decided to first discuss the requirements for the migration project in a holistic view. We defined what our main objectives were at the very start:\nHave ability to execute tests in Excel instead of Oracle and remove the dependencies on the Oracle DB Have better reporting of test cases to Azure DevOps, send emails, and be able to provide good graphs of results Configurations for features available to be configurable as code. Easy ability to turn on and off features. As I began the project, I discussed daily enhancements with the team and developed the framework slowly but surely. I listed all our advancements and features on Azure DevOps and tracked over 400 work items prioritizing high priority items to 1 and lower ones to 4. I also included latest ideas as things to “Investigate” such as integrations with other common tools.\nRun results of executions. Technical Problems Importing Oracle Database Data into a Viewable Format When we look at an Oracle Database table, it is just like any relational database. The data is stored on one table, but you cannot get one list of everything ordered correctly. So, if we simply exported the table from SQL Developer it would be thousands of lines of unordered test steps. We wanted to be able to extract and then immediately run the tests directly from the XML, TXT, CSV, or Excel that it was extracted into.\nThe problem with XML and TXT is that it is not configurable per column. We wanted to be able to interact with columns and update columns quickly.\nThis led us to believe that Excel running an .xlsx or .csv was the right choice. We also wanted to add triggers for validations of columns just like how we had in Oracle.\nWe also found that some of our values in the Oracle had commas built in, so exporting it may cause issues with the tests. We could overwrite the values, but we also knew that some validations required the checks of commas. The benefit of CSV would be that we would be able to perform proper version control on the values as they were in plaintext.\nIn the end, we started with the idea of moving all the test definitions to Excel by building a program to grab test case steps and test suite steps from ALM, creating excel binaries using an Excel library, querying Oracle using client libraries for the test steps and then inputting the data into Excel. I called this the ALM Migrator.\nFor ease of users of the ALM Migrator, I built the framework and added it to a network drive. Then modified the VBA scripts in ALM to add a button that we execute the framework from the network drive to report results into the local user’s C drive.\nReading Excel Data The next problem I faced was in reading excel test data. There was a builder model in the framework outline which did not include implementations for Excel. Since our framework outline had been published into NuGet packages which were segregated, I decided to download our binaries and rebuild them locally. This is the idea of a mono repo.\nI ran a debugger and turned off Just My Code which allowed me to understand what was causing issues with the framework. Eventually I got the framework to read the Test Suite named by the excel name, read the Test Cases within the Excel, and then read the Test Steps inside excel. I finally was able to make the framework work by just reading, but executing was still a big question mark.\nExecuting Data As I began trying to run our Testing Driver, I was perplexed. How does our framework interact with the browsers, what are chrome drivers? Definitions of implicit vs explicit waits, how many attempts, timeouts, Selenium drivers, compilation modes, and what are AODA (Accessibility for Ontarians with Disabilities Act) drivers.\nIn addition, took a long time to understand how our frameworks’ action on objects were interacting with the Selenium Driver and the Chrome Drivers which we installed. Figuring out how the drivers worked was the biggest learning curve.\nSlowly but surely though I was able to make the Automation program build and run.\nFunctionality Development For developing features, I focused on making feature flags available to end users. This enables us to create unique features so that if something breaks, the framework itself will still work. Some features I added were the abilities to report test results to DevOps, report results to Micro Focus ALM, report results to CSV, run AODA reports, highlight elements, enable VNC video, enable PDF reports, enable emailed reports, and to report to Report Portal. If one day one of the features stops working, all the QA team needs to do is turn off the feature in app.config.\nUnit Tests I put a lot of emphasis on building good unit tests and expanding our code coverage for the unit tests. When we have high coverage, we can be more confident that the framework is doing its job. Writing good unit tests allows us to be able to make more releases and iterate at a faster rate.\nAuthorization and Authentication For authorization and authentication, I worked on support for three main methods. The first method was through an Excel file for storing credentials. The second method was through hard coded values, and the third method was through Azure Key Vault. The mechanisms for all three allow any QA team to operate efficiently and allow for any project team to use the framework.\nAzure DevOps For Azure DevOps, I worked extensively with the Azure DevOps Test Management API and SDK to report test results to DevOps. I sent API requests to check for Test Plan, Test Case, Test Step, and Test Run existences in DevOps. If any of those did not exist, then I would create another request to create them. Finally, I would combine everything into a Test Run involving Azure Test Points to generate a test instance. The execution involves running test steps, reporting results to the test case, running the next test case until none exists, then reporting results to the test set. This idea of building separately and running separately is the backbone of the test automation framework that we developed.\nResults Reporting Result reporting was a huge challenge at first in Azure DevOps. There was always duplication of Test Case and Test Plan details, and the results were not clear. I worked on making the results more aligned and preventing duplication of results. I ran into batching issues which is when REST API is overloading. I overcame this by using client libraries instead of APIs which enabled batching requests. I also enabled async functionalities where possible.\nI worked on email reporting and designing robust copies of execution results via email. I created an HTML template for results reporting which would be filled out at the end of the execution. Then I created two copies of the HTML: one that could be embedded in an email (static html) and one which could have embedded JavaScript for viewing results in an accordion.\nDeployment of Code This took a long time to understand. Initially, I packaged the framework and threw it into a network drive. I also created a self-extracting zip file and msi files for users to navigate through. I created bash scripts, power shell scripts, and other scheduled scripts to execute tests. I also created excels with embedded VBA to execute tests. At some point I also created a C# windows application that would allow users to interact with the executable.\nHowever, this turned out to be hard to use and difficult to view central results. I eventually landed on the benefits of using the Azure pipelines and agent pools to deploy the code to on-prem machines. My manager and I managed to install agents on all our on-prem machines and then deploy the latest framework to those machines. I investigated publishing NuGet packages and creating binaries for users to use. I also investigated the possibilities of creating Artifacts in DevOps and sending them to users.\nI spent a lot of time developing pipelines and creating parallel executions available in Azure DevOps. I played around with Deployment Pools, Agent Pools, and Azure Pipelines quite a bit to figure out how to deploy the testing framework to users.\nThe idea that I landed on was to deploy the framework’s-built code to self-hosted agents on QA servers, then reference that path on a different pipeline’s executable. If the latest framework is deployed to the right folder, we will not have to worry about deploying the framework manually.\nDocumentation I started a markdown readme format for documentation. I enabled our wiki to have documentation which could be referenced and sent to all teams. I created mechanisms for users to report bugs in the framework and for users to fix bugs. I wrote documentation on how users can create Work Items and then how to triage them. I also created some KT videos, ran KT sessions, and interacted with QA teams for requirements gathering.\nData Files I worked converting Oracle Database tables into Excel, but I also worked with XML and JSON interpretations of the framework. The problem with non-column centered formats was that it was hard to interact with the tests. For Excel based test steps, it is easy to delete, add, and remove test steps.\nSQL Enhancements I worked on SQL enhancements so that applications could be restarted at their initial states. I worked on developing scripts that reset states to Open or Input from Closed or Submitted states. This avoided having to run DB refreshes and allowed tests to start from the same initial state every time.\nParameterization I wanted to enable parameterization of testing so that tests could be executed with minor changes but still work. Especially with the format of our tests where a year could change a lot of tests, it was imperative that users could easily change the year with a parameter. I also wanted to enable uniqueness of tests so provided a default unique value which could be used for each test execution.\nBrowsers I investigated browser issues such as driver issues. I investigated updating test binaries from chromium to chrome for testing to the default browsers installed. I spent a lot of effort into determining how to isolate browsers and enable execution isolation and environment segregation. I wanted to avoid flaky tests and enable automation results to be more robust.\nPackaging For packaging, I first looked at how we could manage packaging through zip files. Then zip files are shared through a network drive. Then through Azure DevOps artifacts. Then through git. And then finally through Azure DevOps Agents.\nWhy BDD is Something That I Endorse More Behavior Driven Development (BDD) is an especially important discussion in 2024. The Keyword Driven model is, to be honest, difficult to map requirements and hard for QAs to understand the WHY as tests are created. At the end of the day, QA testing should be focused on what the actual users will experience and NOT on what the application is behaving.\nIf I were to rewrite the framework, I would have thought about doing BDD with Playwright instead of spending hours working on fixing a program which did Keyword Driven Testing.\nPlaywright I worked with another colleague on running a Playwright POC and testing out how to integrate Playwright with our framework. Overall, we enabled Playwright with our framework. However, I do believe that Playwright could even be usable out of the box without additional configurations. If I were to re-start automation efforts, I would combine Playwright and BDD into a new framework.\nSummary Overall, this project was an incredibly fun project which allowed me to experience developing working software from start to finish. During the project, I learned everything from writing reusable software, building, and deploying software, getting requirements and feedback, and creating new features.\n","wordCount":"2973","inLanguage":"en","image":"http://localhost:1313/posts/post-files/internships/test-automation-view.png","datePublished":"2024-09-02T12:31:16-04:00","dateModified":"2024-09-02T12:31:16-04:00","author":{"@type":"Person","name":"Victor Zheng"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/automation-framework/"},"publisher":{"@type":"Organization","name":"Victor Zheng","logo":{"@type":"ImageObject","url":"https://github.com/victor-zheng-codes/Personal-Website/blob/main/static/chess_design_favicon.png?raw=true"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Victor Zheng (Alt + H)">Victor Zheng</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=http://localhost:1313/posts/ title=Posts><span>Posts</span></a></li><li><a href=http://localhost:1313/about/ title=About><span>About</span></a></li><li><a href=http://localhost:1313/archives/ title=Archive><span>Archive</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class=post-title>Testing Automation Framework</h1><div class=post-meta>&lt;span title='2024-09-02 12:31:16 -0400 EDT'>September 2, 2024&lt;/span>&amp;nbsp;·&amp;nbsp;14 min&amp;nbsp;·&amp;nbsp;2973 words&amp;nbsp;·&amp;nbsp;Victor Zheng&nbsp;|&nbsp;<a href=https://github.com/victor-zheng-codes/Personal-Website/tree/main/content/posts/automation-framework.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=lazy src=http://localhost:1313/posts/post-files/internships/test-automation-view.png alt><p></p></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#background>Background</a></li><li><a href=#why-azure-devops>Why Azure DevOps</a></li><li><a href=#why-i-took-up-the-project>Why I took up the project</a></li><li><a href=#technical-problems>Technical Problems</a><ul><li><a href=#importing-oracle-database-data-into-a-viewable-format>Importing Oracle Database Data into a Viewable Format</a></li><li><a href=#reading-excel-data>Reading Excel Data</a></li><li><a href=#executing-data>Executing Data</a></li><li><a href=#functionality-development>Functionality Development</a></li><li><a href=#unit-tests>Unit Tests</a></li><li><a href=#authorization-and-authentication>Authorization and Authentication</a></li><li><a href=#azure-devops>Azure DevOps</a></li><li><a href=#results-reporting>Results Reporting</a></li><li><a href=#deployment-of-code>Deployment of Code</a></li><li><a href=#documentation>Documentation</a></li><li><a href=#data-files>Data Files</a></li><li><a href=#sql-enhancements>SQL Enhancements</a></li><li><a href=#parameterization>Parameterization</a></li><li><a href=#browsers>Browsers</a></li><li><a href=#packaging>Packaging</a></li><li><a href=#why-bdd-is-something-that-i-endorse-more>Why BDD is Something That I Endorse More</a></li><li><a href=#playwright>Playwright</a></li></ul></li><li><a href=#summary>Summary</a></li></ul></nav></div></details></div><div class=post-content><h1 id=test-automation-framework>Test Automation Framework<a hidden class=anchor aria-hidden=true href=#test-automation-framework>#</a></h1><p>The Test Automation Program was one of the main projects that I worked on while at the Ministry of Education of the Government of Ontario.</p><p>The code is open-source and is a comprehensive, end-to-end testing framework for UI testing and reporting. The original developers had a multi-repo model which I combined into a mono-repo to enable easier versioning, feature enhancements, and documentation.</p><p>The full, open-source framework is available here: <a href=https://github.com/zzzrst/AutomationTestingProgram>github.com/zzzrst/AutomationTestingProgram</a>.</p><p>All thoughts are my own and I have redacted any personal information and team information. The main goal for all my blogs is to provide a personal reflection of different years of my life.</p><h2 id=background>Background<a hidden class=anchor aria-hidden=true href=#background>#</a></h2><p>The framework is Keyword Driven, with Selenium 4.0 running in the background and abstractions made to make it executable with test steps defined in Excel or Oracle. The thinking for making test step definitions defined in Excel is that it allows for the ease of sending the file via email, and for the non-technical team members to use the framework for testing. The need to understand how the scripting is done is abstracted and so PM or someone with no technical knowledge can still generate and understand tests. See my section below on BDD for some thoughts on this though.</p><p>The framework interacts with the Oracle DB or Excel test cases before parsing the results into Test Step, Test Suites, and Test Sets using the builder design pattern. Each Test Suite is built, then Test Cases are added to the Test Suite, and then Test Steps are added to the Test Case. When we execute the tests, we start from the Test Steps and report results to the Test Case, which in turn reports back to the Test Suite. The framework would read the ALM Test Suite and Test Case definitions, query the Oracle DB within one table for the test step ordering, and then execute the test via C#. Before reporting results to ALM or any other testing reporting platform.</p><p>The framework also allows for a Traceability Matrix to be used to map requirements for testing. Traceability is usually done in an Excel file and mapped directly to test cases and steps which can be in a separate tab in the same Excel.</p><p>When I first joined the team at the Ministry of Education, we were working with an Oracle Database which stored our test cases alongside Micro Focus’ ALM project management platform. As in all companies, migration projects are always underway.</p><p>We were moving to Microsoft’s SharePoint Online from on-prem SharePoint and to Azure DevOps from Microsoft TFS. With Azure DevOps, work items would be logged into DevOps and manual tests would also no longer be done in ALM.</p><p>Therefore, there was a necessary need to investigate how we could migrate our tests to Azure DevOps and get results published to Azure DevOps instead of simply ALM. The quest began to build this new framework.</p><h2 id=why-azure-devops>Why Azure DevOps<a hidden class=anchor aria-hidden=true href=#why-azure-devops>#</a></h2><p>Microsoft Azure is the future, and it enables continuous integration and continuous delivery, which will speed up product delivery, and bring development to production timelines faster. The barrier between development and operations teams will drastically decrease and we can more quickly iterate to build better products. Using TFS, we would never be able to say we are Agile as we would always be waiting for gates to be approved and deployments to be manually executed.</p><p>Micro Focus’ ALM is an on-prem server, which is hard to use, difficult to configure, and filled with buttons which we will never need to use and are hard to understand. It runs very slowly, does not store build/deployment information, and does not have a linkage between code and executions. It also does not allow us to link test cases to different builds, so we are not 100% sure that the tests we are executing are in the right environments. Setting up ALM itself requires a ton of configuring and downloading archaic software from the web.</p><p>When we use Azure DevOps (like Jira), we can directly see the linkage between defects and code changes. It also has many integrations with popular products directly from its marketplace. It has task groups available, and agent pools for deployment. It is Team Foundation Server but much more modern and with Git. The main benefit, however, is that it is on the cloud and accessible with any web browser. This means that simply accessing defects does not take a few minutes and logging issues can be quick and simple. It is a modern approach to software development.</p><h2 id=why-i-took-up-the-project>Why I took up the project<a hidden class=anchor aria-hidden=true href=#why-i-took-up-the-project>#</a></h2><p>At first, I wanted to understand how ALM communicated with Oracle and how the Selenium running in the background worked. However, I also noticed that our methodologies were lacking some major items such as version control, ease of updating, and the ability to see the big picture. I also had major questions about how to update the framework to fit the needs of QA teams. For instance, I remember asking how we could update browser versions or add new features to execute scripts against an Oracle DB. In addition, the need to interact with a database using SQL is not easy. Looking at a table in a database does not give you information on what is being run. One month into my internship, I landed on the migration project and some initial source-code of a framework which was discussed 5 years ago. The blueprint was there, but the framework still was not finished. The framework needed major tune-ups and fixing so that it would be usable with the modern-day approaches.</p><p>How I managed the project</p><p>Personally, I excel in ambiguous projects which require careful thinking, strategizing, and planning to achieve. However, the main problem with ambiguity is that there is not always a clear idea of what needs to be done. My manager and my team decided to first discuss the requirements for the migration project in a holistic view. We defined what our main objectives were at the very start:</p><ul><li>Have ability to execute tests in Excel instead of Oracle and remove the dependencies on the Oracle DB</li><li>Have better reporting of test cases to Azure DevOps, send emails, and be able to provide good graphs of results</li><li>Configurations for features available to be configurable as code. Easy ability to turn on and off features.</li></ul><p>As I began the project, I discussed daily enhancements with the team and developed the framework slowly but surely. I listed all our advancements and features on Azure DevOps and tracked over 400 work items prioritizing high priority items to 1 and lower ones to 4. I also included latest ideas as things to “Investigate” such as integrations with other common tools.</p><table><thead><tr><th style=text-align:center><img loading=lazy src=/posts/post-files/internships/RunResults.png alt></th></tr></thead><tbody><tr><td style=text-align:center>Run results of executions.</td></tr></tbody></table><h2 id=technical-problems>Technical Problems<a hidden class=anchor aria-hidden=true href=#technical-problems>#</a></h2><h3 id=importing-oracle-database-data-into-a-viewable-format>Importing Oracle Database Data into a Viewable Format<a hidden class=anchor aria-hidden=true href=#importing-oracle-database-data-into-a-viewable-format>#</a></h3><p>When we look at an Oracle Database table, it is just like any relational database. The data is stored on one table, but you cannot get one list of everything ordered correctly. So, if we simply exported the table from SQL Developer it would be thousands of lines of unordered test steps. We wanted to be able to extract and then immediately run the tests directly from the XML, TXT, CSV, or Excel that it was extracted into.</p><p>The problem with XML and TXT is that it is not configurable per column. We wanted to be able to interact with columns and update columns quickly.</p><p>This led us to believe that Excel running an .xlsx or .csv was the right choice. We also wanted to add triggers for validations of columns just like how we had in Oracle.</p><p>We also found that some of our values in the Oracle had commas built in, so exporting it may cause issues with the tests. We could overwrite the values, but we also knew that some validations required the checks of commas. The benefit of CSV would be that we would be able to perform proper version control on the values as they were in plaintext.</p><p>In the end, we started with the idea of moving all the test definitions to Excel by building a program to grab test case steps and test suite steps from ALM, creating excel binaries using an Excel library, querying Oracle using client libraries for the test steps and then inputting the data into Excel. I called this the ALM Migrator.</p><p>For ease of users of the ALM Migrator, I built the framework and added it to a network drive. Then modified the VBA scripts in ALM to add a button that we execute the framework from the network drive to report results into the local user’s C drive.</p><h3 id=reading-excel-data>Reading Excel Data<a hidden class=anchor aria-hidden=true href=#reading-excel-data>#</a></h3><p>The next problem I faced was in reading excel test data. There was a builder model in the framework outline which did not include implementations for Excel. Since our framework outline had been published into NuGet packages which were segregated, I decided to download our binaries and rebuild them locally. This is the idea of a mono repo.</p><p>I ran a debugger and turned off Just My Code which allowed me to understand what was causing issues with the framework. Eventually I got the framework to read the Test Suite named by the excel name, read the Test Cases within the Excel, and then read the Test Steps inside excel. I finally was able to make the framework work by just reading, but executing was still a big question mark.</p><h3 id=executing-data>Executing Data<a hidden class=anchor aria-hidden=true href=#executing-data>#</a></h3><p>As I began trying to run our Testing Driver, I was perplexed. How does our framework interact with the browsers, what are chrome drivers? Definitions of implicit vs explicit waits, how many attempts, timeouts, Selenium drivers, compilation modes, and what are AODA (Accessibility for Ontarians with Disabilities Act) drivers.</p><p>In addition, took a long time to understand how our frameworks’ action on objects were interacting with the Selenium Driver and the Chrome Drivers which we installed. Figuring out how the drivers worked was the biggest learning curve.</p><p>Slowly but surely though I was able to make the Automation program build and run.</p><h3 id=functionality-development>Functionality Development<a hidden class=anchor aria-hidden=true href=#functionality-development>#</a></h3><p>For developing features, I focused on making feature flags available to end users. This enables us to create unique features so that if something breaks, the framework itself will still work. Some features I added were the abilities to report test results to DevOps, report results to Micro Focus ALM, report results to CSV, run AODA reports, highlight elements, enable VNC video, enable PDF reports, enable emailed reports, and to report to Report Portal. If one day one of the features stops working, all the QA team needs to do is turn off the feature in app.config.</p><h3 id=unit-tests>Unit Tests<a hidden class=anchor aria-hidden=true href=#unit-tests>#</a></h3><p>I put a lot of emphasis on building good unit tests and expanding our code coverage for the unit tests. When we have high coverage, we can be more confident that the framework is doing its job. Writing good unit tests allows us to be able to make more releases and iterate at a faster rate.</p><h3 id=authorization-and-authentication>Authorization and Authentication<a hidden class=anchor aria-hidden=true href=#authorization-and-authentication>#</a></h3><p>For authorization and authentication, I worked on support for three main methods. The first method was through an Excel file for storing credentials. The second method was through hard coded values, and the third method was through Azure Key Vault. The mechanisms for all three allow any QA team to operate efficiently and allow for any project team to use the framework.</p><h3 id=azure-devops>Azure DevOps<a hidden class=anchor aria-hidden=true href=#azure-devops>#</a></h3><p>For Azure DevOps, I worked extensively with the Azure DevOps Test Management API and SDK to report test results to DevOps. I sent API requests to check for Test Plan, Test Case, Test Step, and Test Run existences in DevOps. If any of those did not exist, then I would create another request to create them. Finally, I would combine everything into a Test Run involving Azure Test Points to generate a test instance. The execution involves running test steps, reporting results to the test case, running the next test case until none exists, then reporting results to the test set. This idea of building separately and running separately is the backbone of the test automation framework that we developed.</p><h3 id=results-reporting>Results Reporting<a hidden class=anchor aria-hidden=true href=#results-reporting>#</a></h3><p>Result reporting was a huge challenge at first in Azure DevOps. There was always duplication of Test Case and Test Plan details, and the results were not clear. I worked on making the results more aligned and preventing duplication of results. I ran into batching issues which is when REST API is overloading. I overcame this by using client libraries instead of APIs which enabled batching requests. I also enabled async functionalities where possible.</p><p>I worked on email reporting and designing robust copies of execution results via email. I created an HTML template for results reporting which would be filled out at the end of the execution. Then I created two copies of the HTML: one that could be embedded in an email (static html) and one which could have embedded JavaScript for viewing results in an accordion.</p><h3 id=deployment-of-code>Deployment of Code<a hidden class=anchor aria-hidden=true href=#deployment-of-code>#</a></h3><p>This took a long time to understand. Initially, I packaged the framework and threw it into a network drive. I also created a self-extracting zip file and msi files for users to navigate through. I created bash scripts, power shell scripts, and other scheduled scripts to execute tests. I also created excels with embedded VBA to execute tests. At some point I also created a C# windows application that would allow users to interact with the executable.</p><p>However, this turned out to be hard to use and difficult to view central results. I eventually landed on the benefits of using the Azure pipelines and agent pools to deploy the code to on-prem machines. My manager and I managed to install agents on all our on-prem machines and then deploy the latest framework to those machines. I investigated publishing NuGet packages and creating binaries for users to use. I also investigated the possibilities of creating Artifacts in DevOps and sending them to users.</p><p>I spent a lot of time developing pipelines and creating parallel executions available in Azure DevOps. I played around with Deployment Pools, Agent Pools, and Azure Pipelines quite a bit to figure out how to deploy the testing framework to users.</p><p>The idea that I landed on was to deploy the framework’s-built code to self-hosted agents on QA servers, then reference that path on a different pipeline’s executable. If the latest framework is deployed to the right folder, we will not have to worry about deploying the framework manually.</p><h3 id=documentation>Documentation<a hidden class=anchor aria-hidden=true href=#documentation>#</a></h3><p>I started a markdown readme format for documentation. I enabled our wiki to have documentation which could be referenced and sent to all teams. I created mechanisms for users to report bugs in the framework and for users to fix bugs. I wrote documentation on how users can create Work Items and then how to triage them. I also created some KT videos, ran KT sessions, and interacted with QA teams for requirements gathering.</p><h3 id=data-files>Data Files<a hidden class=anchor aria-hidden=true href=#data-files>#</a></h3><p>I worked converting Oracle Database tables into Excel, but I also worked with XML and JSON interpretations of the framework. The problem with non-column centered formats was that it was hard to interact with the tests. For Excel based test steps, it is easy to delete, add, and remove test steps.</p><h3 id=sql-enhancements>SQL Enhancements<a hidden class=anchor aria-hidden=true href=#sql-enhancements>#</a></h3><p>I worked on SQL enhancements so that applications could be restarted at their initial states. I worked on developing scripts that reset states to Open or Input from Closed or Submitted states. This avoided having to run DB refreshes and allowed tests to start from the same initial state every time.</p><h3 id=parameterization>Parameterization<a hidden class=anchor aria-hidden=true href=#parameterization>#</a></h3><p>I wanted to enable parameterization of testing so that tests could be executed with minor changes but still work. Especially with the format of our tests where a year could change a lot of tests, it was imperative that users could easily change the year with a parameter. I also wanted to enable uniqueness of tests so provided a default unique value which could be used for each test execution.</p><h3 id=browsers>Browsers<a hidden class=anchor aria-hidden=true href=#browsers>#</a></h3><p>I investigated browser issues such as driver issues. I investigated updating test binaries from chromium to chrome for testing to the default browsers installed. I spent a lot of effort into determining how to isolate browsers and enable execution isolation and environment segregation. I wanted to avoid flaky tests and enable automation results to be more robust.</p><h3 id=packaging>Packaging<a hidden class=anchor aria-hidden=true href=#packaging>#</a></h3><p>For packaging, I first looked at how we could manage packaging through zip files. Then zip files are shared through a network drive. Then through Azure DevOps artifacts. Then through git. And then finally through Azure DevOps Agents.</p><h3 id=why-bdd-is-something-that-i-endorse-more>Why BDD is Something That I Endorse More<a hidden class=anchor aria-hidden=true href=#why-bdd-is-something-that-i-endorse-more>#</a></h3><p>Behavior Driven Development (BDD) is an especially important discussion in 2024. The Keyword Driven model is, to be honest, difficult to map requirements and hard for QAs to understand the WHY as tests are created. At the end of the day, QA testing should be focused on what the actual users will experience and NOT on what the application is behaving.</p><p>If I were to rewrite the framework, I would have thought about doing BDD with Playwright instead of spending hours working on fixing a program which did Keyword Driven Testing.</p><h3 id=playwright>Playwright<a hidden class=anchor aria-hidden=true href=#playwright>#</a></h3><p>I worked with another colleague on running a Playwright POC and testing out how to integrate Playwright with our framework. Overall, we enabled Playwright with our framework. However, I do believe that Playwright could even be usable out of the box without additional configurations. If I were to re-start automation efforts, I would combine Playwright and BDD into a new framework.</p><h2 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h2><p>Overall, this project was an incredibly fun project which allowed me to experience developing working software from start to finish. During the project, I learned everything from writing reusable software, building, and deploying software, getting requirements and feedback, and creating new features.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=next href=http://localhost:1313/posts/internship-td-2024/><span class=title>Next »</span><br><span>Internship at the Toronto Dominion Bank Jan 2024 - April 2024</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Victor Zheng</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>